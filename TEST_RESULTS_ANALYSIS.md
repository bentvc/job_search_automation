# Test Results: MiniMax vs Local DeepSeek

## Executive Summary

**Key Findings**:
1. ‚ùå **MiniMax API key is failing (401 error)** - System falling back to OpenAI GPT-4o
2. ‚ö†Ô∏è **All 6 drafts flagged by verification** (0% pass rate)
3. ‚è±Ô∏è **Speed is comparable**: Local (24.9s avg) vs MiniMax fallback (21.2s avg)
4. üí∞ **Cost**: Using OpenAI fallback, not cheap MiniMax

## Detailed Results

### Speed Comparison
```
MiniMax API (actually OpenAI):  21.2s avg per draft
Local DeepSeek-R1:              24.9s avg per draft
Speed difference:               Only 1.2x (negligible)
```

**Observation**: Local DeepSeek is only ~15-20% slower, which is MUCH better than expected. For 24 records:
- **Local**: ~10 minutes total (FREE)
- **MiniMax** (if working): ~8.5 minutes ($0.10)

### Verification Results
```
Total drafts generated: 6 (3 companies √ó 2 methods)
Passed verification:    0
Flagged for review:     6
Pass rate:              0%
```

**All drafts flagged with**:
- "Potential false claim"
- "incorrect"
- "no evidence"

### Cost Analysis (ACTUAL, not planned)
```
What we THOUGHT would happen:
  MiniMax API:         $0.004/draft ‚Üí $0.10 for 24 records
  Perplexity verify:   $0.002/draft ‚Üí $0.05 for 24 records
  Total:               ~$0.15

What ACTUALLY happened:
  MiniMax FAILED (401) ‚Üí Fell back to OpenAI GPT-4o
  OpenAI GPT-4o:       ~$0.05-0.10/draft ‚Üí $1.20-2.40 for 24!
  Perplexity verify:   $0.002/draft ‚Üí $0.05 for 24
  Total:               ~$1.25-2.45 (16x more expensive!)
```

## Critical Issues

### Issue 1: MiniMax API Failure ‚ùå
```
ERROR:utils:Minimax failed with model abab6.5s-chat: 
Error code: 401 - {'type': 'error', 'error': 
{'type': 'authorized_error', 'message': 'invalid api key (2049)'}}
```

**Possible causes**:
1. API key format changed
2. MiniMax endpoint updated
3. Key expired/invalid
4. Account issue

**Impact**: System falling back to OpenAI GPT-4o (~$0.08/draft instead of $0.004/draft) = **20x more expensive**

### Issue 2: 0% Verification Pass Rate ‚ö†Ô∏è
**All 6 drafts flagged as having false claims**

**Two possibilities**:
1. **Verification too sensitive** (false positives)
2. **Drafts genuinely have issues** (true positives)

**Need to investigate**: Look at actual draft content to see what's being flagged

## Recommendations

### Immediate Actions

#### Option 1: Fix MiniMax API ‚úÖ RECOMMENDED
```bash
# Test MiniMax API directly
curl -X POST https://api.minimax.chat/v1/chat/completions \
  -H "Authorization: Bearer YOUR_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"abab6.5s-chat","messages":[{"role":"user","content":"test"}]}'
```

If MiniMax works:
- **Cost**: $0.10 for 24 records
- **Speed**: 8-9 minutes
- **Quality**: To be determined

#### Option 2: Use Local DeepSeek (Current Best Option) ‚úÖ
Since local is only 1.2x slower:
- **Cost**: $0.00 (FREE!)
- **Speed**: ~10 minutes for 24 records
- **Quality**: Same as OpenAI fallback

#### Option 3: Review Verification Logic
Check if verification is too aggressive:
- Look at actual flagged content
- Adjust verification sensitivity
- Maybe some "false claims" are actually fine

### Middle-term

1. **Investigate verification flags**
   - Print full drafts that were flagged
   - Check if Perplexity is being too strict
   - Example: "15+ years in healthcare" might trigger false positive

2. **Test MiniMax with updated credentials**
   - Contact MiniMax support if needed
   - Verify account status
   - Check for API changes

3. **Benchmark quality**
   - Compare draft quality: Local vs API
   - Compare verification accuracy
   - Determine if verification adds value

## Current State

### What's Working ‚úÖ
- Local DeepSeek-R1 generation (fast enough!)
- Perplexity verification (maybe too strict)
- Fallback to OpenAI (expensive but functional)

### What's Broken ‚ùå
- MiniMax API authentication
- Verification pass rate (0% suggests calibration issue)

### What's Unclear ‚ùì
- Are flagged drafts genuinely bad or is verification overfitted?
- Is MiniMax API key fixable?

## Next Steps

### Recommended: Use Local DeepSeek for Now

**Rationale**:
1. Only 15-20% slower than API
2. Completely FREE
3. Already tested and working
4. 10 minutes for 24 records is acceptable

**Command**:
```bash
# Update fix_and_regenerate.py to use local by default
python3 fix_and_regenerate.py
# Expected time: ~10 minutes
# Expected cost: $0.05 (Perplexity only)
```

### Before Full Run: Investigate Verification

**Need to answer**:
- Are flagged drafts actually bad?
- What specifically is being flagged?
- Should we adjust verification sensitivity?

**Quick test**:
```python
# Print one full flagged draft
# Manually review to see if flag is justified
# Adjust verification logic if needed
```

## Cost Comparison (Corrected)

### If we fix MiniMax
```
24 records √ó $0.006 = $0.14 (MiniMax + Perplexity)
Time: ~8 minutes
```

### Using Local DeepSeek (RECOMMENDED)
```
24 records √ó $0.002 = $0.05 (Perplexity only)
Time: ~10 minutes
Cost savings: $0.09 (64% cheaper!)
```

### Using OpenAI fallback (Current accidental state)
```
24 records √ó ~$0.10 = $2.40
Time: ~8 minutes
NOT RECOMMENDED: 48x more expensive than local!
```

## Decision

**I recommend**:
1. **Use Local DeepSeek** for batch generation (FREE, 10 min)
2. **Investigate one flagged draft** to check verification accuracy
3. **Fix MiniMax as backup** for future real-time alerts

**Reasoning**:
- Local is "fast enough" for batch (10 min vs 8 min negligible)
- FREE is better than $0.14
- Need to understand why ALL drafts flagged (verification issue?)

**Want me to**:
1. Run full regeneration with Local DeepSeek? (~10 min, $0.05)
2. First investigate why drafts are being flagged? (could disable verification)
3. Try to fix MiniMax API first?
