nohup: ignoring input
ü§ñ AUTOMATED PIPELINE ORCHESTRATION
================================================
Started at: Thu Jan 22 03:49:32 PM MST 2026

‚è≥ [Phase 1] Waiting for Multi-Site Scraper to complete...
   (This is already running in background)

   Still scraping... (15:49:42)
   Still scraping... (15:49:52)
   Still scraping... (15:50:02)
   Still scraping... (15:50:12)
‚úÖ Multi-Site Scraper complete!

ü§ñ [Phase 2] Batch LLM Scoring (all unscored jobs)...
INFO:__main__:üìä Batch scoring 20 jobs...
INFO:__main__:Batch 1/1 (20 jobs)
WARNING:__main__:MiniMax failed: 200, falling back to DeepSeek
INFO:__main__:Using DeepSeek fallback...
INFO:utils:Discovered best openai model: gpt-4o
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
WARNING:__main__:DeepSeek returned unexpected format
WARNING:__main__:Batch 1 failed completely, skipping
INFO:__main__:‚úÖ Batch scoring complete: 0 total jobs scored

üöÄ [Phase 3] Y Combinator Healthcare Scraper...
INFO:__main__:üöÄ Launching Y Combinator Healthcare Scraper (FIXED)
INFO:__main__:API extraction failed, trying HTML parsing...
INFO:__main__:‚úÖ YC HTML: Found 0 companies
INFO:__main__:API failed, trying direct HTML scrape...
INFO:__main__:‚úÖ YC HTML: Found 0 companies
ERROR:__main__:All YC scrape methods failed

üéØ [Phase 4] Direct ATS Scraper (Greenhouse + Lever)...
INFO:__main__:üéØ Launching Direct ATS Scraper
INFO:__main__:üìä Targets: 21 companies
INFO:__main__:‚úÖ komodohealth: Found 0 jobs
INFO:__main__:‚úÖ collectivehealth: Found 0 jobs
INFO:__main__:‚úÖ healthverity: Found 0 jobs
INFO:__main__:‚úÖ gravie: Found 19 jobs (Lever)
ERROR:__main__:Error scraping Lever tempus: HTTPSConnectionPool(host='jobs.lever.co', port=443): Read timed out. (read timeout=10)
INFO:__main__:üìä Total scraped: 0 Greenhouse + 19 Lever jobs
INFO:__main__:üíæ Stored 0 greenhouse jobs
INFO:__main__:üíæ Stored 0 lever jobs
INFO:__main__:‚úÖ ATS Scrape Complete: 0 new jobs from career pages

üí∞ [Phase 5] Rock Health Funding Database...
INFO:__main__:üí∞ Launching Rock Health Funding Database Scraper
ERROR:__main__:Rock Health request failed: 404
WARNING:__main__:No companies found from Rock Health

üè• [Phase 6] Healthcare-Specific Job Boards...
INFO:__main__:üè• Launching Healthcare-Specific Job Board Scraper
INFO:__main__:Scraping MedReps...
INFO:__main__:Scraping HealthcareJobSite...
INFO:__main__:‚úÖ HealthcareJobSite: Found 0 jobs
INFO:__main__:Scraping Health eCareers...
INFO:__main__:‚úÖ Health eCareers: Found 0 jobs
INFO:__main__:üìä Total scraped: 0 jobs from niche boards
INFO:__main__:üíæ Stored 0 niche healthcare jobs
INFO:__main__:‚úÖ Niche Boards Complete: 0 new healthcare sales jobs

üì∞ [Phase 7] RSS Funding News Aggregator...
INFO:__main__:üì∞ Launching RSS Funding News Aggregator
INFO:__main__:üì° Fetching techcrunch_healthcare...
INFO:__main__:‚úÖ techcrunch_healthcare: Found 0 funding signals
INFO:__main__:üì° Fetching techcrunch_funding...
INFO:__main__:‚úÖ techcrunch_funding: Found 1 funding signals
INFO:__main__:üì° Fetching fierce_healthcare...
INFO:__main__:‚úÖ fierce_healthcare: Found 3 funding signals
INFO:__main__:üì° Fetching healthcare_finance...
INFO:__main__:‚úÖ healthcare_finance: Found 0 funding signals
INFO:__main__:üì° Fetching mobihealthnews...
INFO:__main__:‚úÖ mobihealthnews: Found 2 funding signals
INFO:__main__:üìä Total signals found: 6
Traceback (most recent call last):
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1811, in _execute_context
    context = constructor(
        dialect, self, conn, execution_options, *args, **kw
    )
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 1485, in _init_compiled
    flattened_processors[key](compiled_params[key])
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/sql/sqltypes.py", line 2792, in process
    return json_serializer(value)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
                    f'is not JSON serializable')
TypeError: Object of type datetime is not JSON serializable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/bent-christiansen/.gemini/antigravity/scratch/job_search_automation/scraper_rss_funding.py", line 178, in <module>
    run_rss_aggregator()
    ~~~~~~~~~~~~~~~~~~^^
  File "/home/bent-christiansen/.gemini/antigravity/scratch/job_search_automation/scraper_rss_funding.py", line 172, in run_rss_aggregator
    companies_created, signals_created = store_funding_signals(all_signals)
                                         ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/bent-christiansen/.gemini/antigravity/scratch/job_search_automation/scraper_rss_funding.py", line 153, in store_funding_signals
    db.commit()
    ~~~~~~~~~^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 2032, in commit
    trans.commit(_to_root=True)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "<string>", line 2, in commit
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1313, in commit
    self._prepare_impl()
    ~~~~~~~~~~~~~~~~~~^^
  File "<string>", line 2, in _prepare_impl
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 1288, in _prepare_impl
    self.session.flush()
    ~~~~~~~~~~~~~~~~~~^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4345, in flush
    self._flush(objects)
    ~~~~~~~~~~~^^^^^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4480, in _flush
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/session.py", line 4441, in _flush
    flush_context.execute()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
    ~~~~~~~~~~~^^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.mapper,
        ^^^^^^^^^^^^
        uow.states_for_mapper_hierarchy(self.mapper, False, False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        uow,
        ^^^^
    )
    ^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        base_mapper,
        ^^^^^^^^^^^^
    ...<3 lines>...
        insert,
        ^^^^^^^
    )
    ^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/orm/persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
        statement, multiparams, execution_options=execution_options
    )
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1415, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/sql/elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1817, in _execute_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str(statement), parameters, None, None
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 2351, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/base.py", line 1811, in _execute_context
    context = constructor(
        dialect, self, conn, execution_options, *args, **kw
    )
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/engine/default.py", line 1485, in _init_compiled
    flattened_processors[key](compiled_params[key])
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/site-packages/sqlalchemy/sql/sqltypes.py", line 2792, in process
    return json_serializer(value)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
  File "/home/bent-christiansen/miniconda3/lib/python3.13/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
                    f'is not JSON serializable')
sqlalchemy.exc.StatementError: (builtins.TypeError) Object of type datetime is not JSON serializable
[SQL: INSERT INTO companies (id, name, domain, vertical, stage, funding_total, employee_count, hq_location, is_bootstrapped, profitability_signal, linkedin_url, crunchbase_url, fit_score, monitoring_status, last_signal_date, signal_score_30d, raw_data) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) RETURNING created_at, updated_at, id]
[parameters: [{'id': '1b561af1-4e77-404c-9e98-a694f8945a6b', 'monitoring_status': 'active', 'raw_data': {'company_name': 'Zipline charts drone delivery expansion wi ... (517 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}, {'id': 'd9d54140-38ff-4c01-ac9b-efbafcf3c732', 'monitoring_status': 'active', 'raw_data': {'company_name': '<a href="https', 'funding': None, 'title': ... (630 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}, {'id': 'e468f23e-02bc-4571-a0cf-49151a477e05', 'monitoring_status': 'active', 'raw_data': {'company_name': '<a href="https', 'funding': '$250M', 'titl ... (628 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}, {'id': '0a3908a4-b58a-4ee2-a677-81fd894f5086', 'monitoring_status': 'active', 'raw_data': {'company_name': '<a href="https', 'funding': None, 'title': ... (564 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}, {'id': '4ad65658-d934-49c6-a3a8-c2f1891ece4a', 'monitoring_status': 'active', 'raw_data': {'company_name': 'OpenEvidence scores $250M', 'funding': Non ... (402 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}, {'id': 'bcfd2356-64d6-480a-93c7-4cdf5f6dee57', 'monitoring_status': 'active', 'raw_data': {'company_name': 'Gates Foundation', 'funding': None, 'title ... (415 characters truncated) ... unding_total': None, 'last_signal_date': None, 'profitability_signal': None, 'domain': None, 'linkedin_url': None, 'hq_location': None, 'stage': None}]]

üîÑ [Phase 8] Syncing Leads & Generating Outreach...
INFO:__main__:Checking universe for 14 high-fit companies...

================================================
üéâ COMPLETE PIPELINE FINISHED
================================================
Completed at: Thu Jan 22 03:50:53 PM MST 2026

üìä FINAL RESULTS:
================================================
Category          Value
----------------  -----
METRIC            COUNT
Total Jobs        361  
New/Unscored      20   
Shortlisted       9    
Active Companies  25   
Funding Signals   0    
Queued Outreach   24   

üìà JOB SOURCES:
indeed|186
linkedin|156
lever|19

üîÑ Restarting Streamlit Dashboard...

‚úÖ All systems operational!
üìä Dashboard: http://localhost:8501
================================================
